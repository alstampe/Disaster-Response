{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ML Pipeline Preparation\n",
    "Follow the instructions below to help you create your ML pipeline.\n",
    "### 1. Import libraries and load data from database.\n",
    "- Import Python libraries\n",
    "- Load dataset from database with [`read_sql_table`](https://pandas.pydata.org/pandas-docs/stable/generated/pandas.read_sql_table.html)\n",
    "- Define feature and target variables X and Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
      "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/wordnet.zip.\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /root/nltk_data...\n",
      "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger.zip.\n",
      "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
     ]
    }
   ],
   "source": [
    "# import libraries\n",
    "import nltk\n",
    "nltk.download(['punkt', 'wordnet', 'averaged_perceptron_tagger'])\n",
    "\n",
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline, FeatureUnion\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer\n",
    "from sqlalchemy import create_engine\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline, FeatureUnion\n",
    "from sklearn.multioutput import MultiOutputClassifier\n",
    "from sklearn.multioutput import ClassifierChain\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sqlalchemy import create_engine\n",
    "import re\n",
    "import pickle\n",
    "import nltk\n",
    "\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.multioutput import MultiOutputClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, make_scorer\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "import warnings\n",
    "\n",
    "import sqlite3 \n",
    "pd.set_option('display.max_column', 999)\n",
    "pd.set_option('display.max_row', 999)\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, make_scorer\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.multioutput import MultiOutputClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, make_scorer\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "import warnings\n",
    "\n",
    "\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.externals import joblib"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load data \n",
    "First step is to establish engine and connection to sqlite to be able to upload the data from process_data.py.\n",
    "\n",
    "Data is read into a dataframe by the load_data function which returns X, y and categories (the category columns )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "engine = create_engine('sqlite:///Database.db')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "conn = sqlite3.connect('Database.db')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "Data=pd.read_sql('SELECT * FROM Data', con = conn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "engine = create_engine('sqlite:///Database.db')\n",
    "conn = engine.connect()\n",
    "df = pd.read_sql(\"SELECT * FROM Data\", con=conn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>message</th>\n",
       "      <th>original</th>\n",
       "      <th>genre</th>\n",
       "      <th>related</th>\n",
       "      <th>request</th>\n",
       "      <th>offer</th>\n",
       "      <th>aid_related</th>\n",
       "      <th>medical_help</th>\n",
       "      <th>medical_products</th>\n",
       "      <th>search_and_rescue</th>\n",
       "      <th>security</th>\n",
       "      <th>military</th>\n",
       "      <th>water</th>\n",
       "      <th>food</th>\n",
       "      <th>shelter</th>\n",
       "      <th>clothing</th>\n",
       "      <th>money</th>\n",
       "      <th>missing_people</th>\n",
       "      <th>refugees</th>\n",
       "      <th>death</th>\n",
       "      <th>other_aid</th>\n",
       "      <th>infrastructure_related</th>\n",
       "      <th>transport</th>\n",
       "      <th>buildings</th>\n",
       "      <th>electricity</th>\n",
       "      <th>tools</th>\n",
       "      <th>hospitals</th>\n",
       "      <th>shops</th>\n",
       "      <th>aid_centers</th>\n",
       "      <th>other_infrastructure</th>\n",
       "      <th>weather_related</th>\n",
       "      <th>floods</th>\n",
       "      <th>storm</th>\n",
       "      <th>fire</th>\n",
       "      <th>earthquake</th>\n",
       "      <th>cold</th>\n",
       "      <th>other_weather</th>\n",
       "      <th>direct_report</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>Weather update - a cold front from Cuba that c...</td>\n",
       "      <td>Un front froid se retrouve sur Cuba ce matin. ...</td>\n",
       "      <td>direct</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7</td>\n",
       "      <td>Is the Hurricane over or is it not over</td>\n",
       "      <td>Cyclone nan fini osinon li pa fini</td>\n",
       "      <td>direct</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id                                            message  \\\n",
       "0   2  Weather update - a cold front from Cuba that c...   \n",
       "1   7            Is the Hurricane over or is it not over   \n",
       "\n",
       "                                            original   genre  related  \\\n",
       "0  Un front froid se retrouve sur Cuba ce matin. ...  direct        1   \n",
       "1                 Cyclone nan fini osinon li pa fini  direct        1   \n",
       "\n",
       "   request  offer  aid_related  medical_help  medical_products  \\\n",
       "0        0      0            0             0                 0   \n",
       "1        1      0            1             0                 0   \n",
       "\n",
       "   search_and_rescue  security  military  water  food  shelter  clothing  \\\n",
       "0                  0         0         0      0     0        0         0   \n",
       "1                  0         0         0      1     0        1         0   \n",
       "\n",
       "   money  missing_people  refugees  death  other_aid  infrastructure_related  \\\n",
       "0      0               0         0      0          0                       0   \n",
       "1      0               0         0      0          0                       0   \n",
       "\n",
       "   transport  buildings  electricity  tools  hospitals  shops  aid_centers  \\\n",
       "0          0          0            0      0          0      0            0   \n",
       "1          0          0            0      0          0      0            0   \n",
       "\n",
       "   other_infrastructure  weather_related  floods  storm  fire  earthquake  \\\n",
       "0                     0                0       0      0     0           0   \n",
       "1                     0                0       0      0     0           0   \n",
       "\n",
       "   cold  other_weather  direct_report  \n",
       "0     0              0              0  \n",
       "1     0              0              1  "
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load_data \n",
    "Function for loading data from the ETL step into a dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data from database\n",
    "def load_data_old():\n",
    "#def load_data_old(database_filepath):\n",
    "    engine = create_engine('sqlite:///Database.db')\n",
    "    conn = sqlite3.connect('Database.db')\n",
    "    pd.read_sql('SELECT * FROM Data', con = conn).head()\n",
    "    df=pd.read_sql('SELECT * FROM Data', con = conn)\n",
    "    X = df.message.values\n",
    "    y = df[df.columns[4:]]\n",
    "    category_names = list(df.columns)\n",
    "       \n",
    "    return df, X, y, category_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data():\n",
    "    engine = create_engine('sqlite:///Database.db')\n",
    "    conn = engine.connect()\n",
    "    df = pd.read_sql(\"SELECT * FROM Data\", con=conn)\n",
    "    X = df['message']\n",
    "    y = df.drop(['id', 'message', 'original', 'genre'], axis = 1)\n",
    "    #category_names = list(df.columns)\n",
    "    category_names = list(y.columns)\n",
    "    return df, X, y, category_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df, X, y, category_names = load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>message</th>\n",
       "      <th>original</th>\n",
       "      <th>genre</th>\n",
       "      <th>related</th>\n",
       "      <th>request</th>\n",
       "      <th>offer</th>\n",
       "      <th>aid_related</th>\n",
       "      <th>medical_help</th>\n",
       "      <th>medical_products</th>\n",
       "      <th>search_and_rescue</th>\n",
       "      <th>security</th>\n",
       "      <th>military</th>\n",
       "      <th>water</th>\n",
       "      <th>food</th>\n",
       "      <th>shelter</th>\n",
       "      <th>clothing</th>\n",
       "      <th>money</th>\n",
       "      <th>missing_people</th>\n",
       "      <th>refugees</th>\n",
       "      <th>death</th>\n",
       "      <th>other_aid</th>\n",
       "      <th>infrastructure_related</th>\n",
       "      <th>transport</th>\n",
       "      <th>buildings</th>\n",
       "      <th>electricity</th>\n",
       "      <th>tools</th>\n",
       "      <th>hospitals</th>\n",
       "      <th>shops</th>\n",
       "      <th>aid_centers</th>\n",
       "      <th>other_infrastructure</th>\n",
       "      <th>weather_related</th>\n",
       "      <th>floods</th>\n",
       "      <th>storm</th>\n",
       "      <th>fire</th>\n",
       "      <th>earthquake</th>\n",
       "      <th>cold</th>\n",
       "      <th>other_weather</th>\n",
       "      <th>direct_report</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>Weather update - a cold front from Cuba that c...</td>\n",
       "      <td>Un front froid se retrouve sur Cuba ce matin. ...</td>\n",
       "      <td>direct</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7</td>\n",
       "      <td>Is the Hurricane over or is it not over</td>\n",
       "      <td>Cyclone nan fini osinon li pa fini</td>\n",
       "      <td>direct</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id                                            message  \\\n",
       "0   2  Weather update - a cold front from Cuba that c...   \n",
       "1   7            Is the Hurricane over or is it not over   \n",
       "\n",
       "                                            original   genre  related  \\\n",
       "0  Un front froid se retrouve sur Cuba ce matin. ...  direct        1   \n",
       "1                 Cyclone nan fini osinon li pa fini  direct        1   \n",
       "\n",
       "   request  offer  aid_related  medical_help  medical_products  \\\n",
       "0        0      0            0             0                 0   \n",
       "1        1      0            1             0                 0   \n",
       "\n",
       "   search_and_rescue  security  military  water  food  shelter  clothing  \\\n",
       "0                  0         0         0      0     0        0         0   \n",
       "1                  0         0         0      1     0        1         0   \n",
       "\n",
       "   money  missing_people  refugees  death  other_aid  infrastructure_related  \\\n",
       "0      0               0         0      0          0                       0   \n",
       "1      0               0         0      0          0                       0   \n",
       "\n",
       "   transport  buildings  electricity  tools  hospitals  shops  aid_centers  \\\n",
       "0          0          0            0      0          0      0            0   \n",
       "1          0          0            0      0          0      0            0   \n",
       "\n",
       "   other_infrastructure  weather_related  floods  storm  fire  earthquake  \\\n",
       "0                     0                0       0      0     0           0   \n",
       "1                     0                0       0      0     0           0   \n",
       "\n",
       "   cold  other_weather  direct_report  \n",
       "0     0              0              0  \n",
       "1     0              0              1  "
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['related',\n",
       " 'request',\n",
       " 'offer',\n",
       " 'aid_related',\n",
       " 'medical_help',\n",
       " 'medical_products',\n",
       " 'search_and_rescue',\n",
       " 'security',\n",
       " 'military',\n",
       " 'water',\n",
       " 'food',\n",
       " 'shelter',\n",
       " 'clothing',\n",
       " 'money',\n",
       " 'missing_people',\n",
       " 'refugees',\n",
       " 'death',\n",
       " 'other_aid',\n",
       " 'infrastructure_related',\n",
       " 'transport',\n",
       " 'buildings',\n",
       " 'electricity',\n",
       " 'tools',\n",
       " 'hospitals',\n",
       " 'shops',\n",
       " 'aid_centers',\n",
       " 'other_infrastructure',\n",
       " 'weather_related',\n",
       " 'floods',\n",
       " 'storm',\n",
       " 'fire',\n",
       " 'earthquake',\n",
       " 'cold',\n",
       " 'other_weather',\n",
       " 'direct_report']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "category_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 22621 entries, 0 to 22620\n",
      "Data columns (total 40 columns):\n",
      "id                        22621 non-null int64\n",
      "message                   22621 non-null object\n",
      "original                  10153 non-null object\n",
      "genre                     22621 non-null object\n",
      "related                   22621 non-null int64\n",
      "request                   22621 non-null int64\n",
      "offer                     22621 non-null int64\n",
      "aid_related               22621 non-null int64\n",
      "medical_help              22621 non-null int64\n",
      "medical_products          22621 non-null int64\n",
      "search_and_rescue         22621 non-null int64\n",
      "security                  22621 non-null int64\n",
      "military                  22621 non-null int64\n",
      "child_alone               22621 non-null int64\n",
      "water                     22621 non-null int64\n",
      "food                      22621 non-null int64\n",
      "shelter                   22621 non-null int64\n",
      "clothing                  22621 non-null int64\n",
      "money                     22621 non-null int64\n",
      "missing_people            22621 non-null int64\n",
      "refugees                  22621 non-null int64\n",
      "death                     22621 non-null int64\n",
      "other_aid                 22621 non-null int64\n",
      "infrastructure_related    22621 non-null int64\n",
      "transport                 22621 non-null int64\n",
      "buildings                 22621 non-null int64\n",
      "electricity               22621 non-null int64\n",
      "tools                     22621 non-null int64\n",
      "hospitals                 22621 non-null int64\n",
      "shops                     22621 non-null int64\n",
      "aid_centers               22621 non-null int64\n",
      "other_infrastructure      22621 non-null int64\n",
      "weather_related           22621 non-null int64\n",
      "floods                    22621 non-null int64\n",
      "storm                     22621 non-null int64\n",
      "fire                      22621 non-null int64\n",
      "earthquake                22621 non-null int64\n",
      "cold                      22621 non-null int64\n",
      "other_weather             22621 non-null int64\n",
      "direct_report             22621 non-null int64\n",
      "dtypes: int64(37), object(3)\n",
      "memory usage: 6.9+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>related</th>\n",
       "      <th>request</th>\n",
       "      <th>offer</th>\n",
       "      <th>aid_related</th>\n",
       "      <th>medical_help</th>\n",
       "      <th>medical_products</th>\n",
       "      <th>search_and_rescue</th>\n",
       "      <th>security</th>\n",
       "      <th>military</th>\n",
       "      <th>water</th>\n",
       "      <th>food</th>\n",
       "      <th>shelter</th>\n",
       "      <th>clothing</th>\n",
       "      <th>money</th>\n",
       "      <th>missing_people</th>\n",
       "      <th>refugees</th>\n",
       "      <th>death</th>\n",
       "      <th>other_aid</th>\n",
       "      <th>infrastructure_related</th>\n",
       "      <th>transport</th>\n",
       "      <th>buildings</th>\n",
       "      <th>electricity</th>\n",
       "      <th>tools</th>\n",
       "      <th>hospitals</th>\n",
       "      <th>shops</th>\n",
       "      <th>aid_centers</th>\n",
       "      <th>other_infrastructure</th>\n",
       "      <th>weather_related</th>\n",
       "      <th>floods</th>\n",
       "      <th>storm</th>\n",
       "      <th>fire</th>\n",
       "      <th>earthquake</th>\n",
       "      <th>cold</th>\n",
       "      <th>other_weather</th>\n",
       "      <th>direct_report</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   related  request  offer  aid_related  medical_help  medical_products  \\\n",
       "0        1        0      0            0             0                 0   \n",
       "1        1        1      0            1             0                 0   \n",
       "2        0        0      0            0             0                 0   \n",
       "3        1        1      0            1             1                 1   \n",
       "4        1        1      0            1             0                 0   \n",
       "\n",
       "   search_and_rescue  security  military  water  food  shelter  clothing  \\\n",
       "0                  0         0         0      0     0        0         0   \n",
       "1                  0         0         0      1     0        1         0   \n",
       "2                  0         0         0      0     0        0         0   \n",
       "3                  0         0         0      0     0        0         0   \n",
       "4                  0         0         0      1     0        0         0   \n",
       "\n",
       "   money  missing_people  refugees  death  other_aid  infrastructure_related  \\\n",
       "0      0               0         0      0          0                       0   \n",
       "1      0               0         0      0          0                       0   \n",
       "2      0               0         0      0          0                       0   \n",
       "3      0               0         0      0          0                       0   \n",
       "4      0               0         0      0          0                       0   \n",
       "\n",
       "   transport  buildings  electricity  tools  hospitals  shops  aid_centers  \\\n",
       "0          0          0            0      0          0      0            0   \n",
       "1          0          0            0      0          0      0            0   \n",
       "2          0          0            0      0          0      0            0   \n",
       "3          0          0            0      0          0      0            0   \n",
       "4          0          0            0      0          0      0            0   \n",
       "\n",
       "   other_infrastructure  weather_related  floods  storm  fire  earthquake  \\\n",
       "0                     0                0       0      0     0           0   \n",
       "1                     0                0       0      0     0           0   \n",
       "2                     0                0       0      0     0           0   \n",
       "3                     0                0       0      0     0           0   \n",
       "4                     0                0       0      0     0           0   \n",
       "\n",
       "   cold  other_weather  direct_report  \n",
       "0     0              0              0  \n",
       "1     0              0              1  \n",
       "2     0              0              0  \n",
       "3     0              0              1  \n",
       "4     0              0              1  "
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Write a tokenization function to process your text data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tokenization\n",
    "The function 'tokenize' will first do a basic clean of the message text strings.\n",
    "The next steps is tokenizing and lemmatizing, performed by imported methods. The functiom returns clean tokens."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(text):\n",
    "\n",
    "    text = re.sub(r\"[^a-zA-Z0-9]\", \" \", text.lower())\n",
    "    tokens = word_tokenize(text)\n",
    "    lemmatizer = WordNetLemmatizer()    \n",
    "\n",
    "    clean_tokens = []\n",
    "    for tok in tokens:\n",
    "        clean_tok = lemmatizer.lemmatize(tok).lower().strip()\n",
    "        clean_tokens.append(clean_tok)\n",
    "   #optional:stemmer    \n",
    "   # stemmer = PorterStemmer()\n",
    "   # stop_words = stopwords.words(\"english\")\n",
    "   # stemmed = [stemmer.stem(word) for word in clean_tokens if word not in stop_words]\n",
    "   #return stemmed\n",
    "\n",
    "   return clean_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['noth', 'eat', 'water', 'starv', 'thirsti']"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenize(df.message[10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Build a machine learning pipeline\n",
    "- You'll find the [MultiOutputClassifier](http://scikit-learn.org/stable/modules/generated/sklearn.multioutput.MultiOutputClassifier.html) helpful for predicting multiple target variables."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Build the model\n",
    "Function 'build_model' builds the pipeline and model, with a set of parameters and a GridSearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = Pipeline([\n",
    "    ('vect', CountVectorizer(tokenizer = tokenize)),\n",
    "    ('tfidf', TfidfTransformer()),\n",
    "    ('clf', MultiOutputClassifier(RandomForestClassifier()))\n",
    "])    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "     steps=[('vect', CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "        ngram_range=(1, 1), preprocessor=None, stop_words=None,\n",
       "        strip...oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False),\n",
       "           n_jobs=1))])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Make test and train sets "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "     steps=[('vect', CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "        ngram_range=(1, 1), preprocessor=None, stop_words=None,\n",
       "        strip...oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False),\n",
       "           n_jobs=1))])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.seed(9)\n",
    "pipeline.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_eval_metrics(actual, predicted, col_names):\n",
    "    \"\"\"Calculate evaluation metrics for ML model\n",
    "    \n",
    "    Args:\n",
    "    actual: array. Array containing actual labels.\n",
    "    predicted: array. Array containing predicted labels.\n",
    "    col_names: list of strings. List containing names for each of the predicted fields.\n",
    "       \n",
    "    Returns:\n",
    "    metrics_df: dataframe. Dataframe containing the accuracy, precision, recall \n",
    "    and f1 score for a given set of actual and predicted labels.\n",
    "    \"\"\"\n",
    "    metrics = []\n",
    "    \n",
    "    # Calculate evaluation metrics for each set of labels\n",
    "    for i in range(len(col_names)):\n",
    "        accuracy = accuracy_score(actual[:, i], predicted[:, i])\n",
    "        precision = precision_score(actual[:, i], predicted[:, i])\n",
    "        recall = recall_score(actual[:, i], predicted[:, i])\n",
    "        f1 = f1_score(actual[:, i], predicted[:, i])\n",
    "        \n",
    "        metrics.append([accuracy, precision, recall, f1])\n",
    "    \n",
    "    # Create dataframe containing metrics\n",
    "    metrics = np.array(metrics)\n",
    "    metrics_df = pd.DataFrame(data = metrics, index = col_names, columns = ['Accuracy', 'Precision', 'Recall', 'F1'])\n",
    "      \n",
    "    return metrics_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                        Accuracy  Precision    Recall        F1\n",
      "related                 0.984266   0.983719  0.995782  0.989714\n",
      "request                 0.974825   0.994380  0.857984  0.921160\n",
      "offer                   0.998575   1.000000  0.692308  0.818182\n",
      "aid_related             0.970194   0.994973  0.933000  0.962990\n",
      "medical_help            0.979694   0.997998  0.745699  0.853596\n",
      "medical_products        0.986166   1.000000  0.728438  0.842886\n",
      "search_and_rescue       0.991984   0.993671  0.702461  0.823067\n",
      "security                0.995309   0.995349  0.732877  0.844181\n",
      "military                0.990381   0.995238  0.723183  0.837675\n",
      "water                   0.983850   0.997558  0.751610  0.857293\n",
      "food                    0.975656   0.995924  0.783957  0.877319\n",
      "shelter                 0.978803   0.998253  0.763017  0.864926\n",
      "clothing                0.995962   0.988827  0.728395  0.838863\n",
      "money                   0.994359   0.996255  0.738889  0.848485\n",
      "missing_people          0.996972   1.000000  0.716667  0.834951\n",
      "refugees                0.990381   0.992574  0.716071  0.831950\n",
      "death                   0.988362   0.998192  0.738956  0.849231\n",
      "other_aid               0.969719   0.991995  0.777678  0.871859\n",
      "infrastructure_related  0.982247   0.998708  0.721755  0.837940\n",
      "transport               0.986759   0.994690  0.718670  0.834447\n",
      "buildings               0.985453   0.998410  0.720183  0.836775\n",
      "electricity             0.994062   1.000000  0.715909  0.834437\n",
      "tools                   0.998397   1.000000  0.737864  0.849162\n",
      "hospitals               0.997328   1.000000  0.744318  0.853420\n",
      "shops                   0.998516   1.000000  0.666667  0.800000\n",
      "aid_centers             0.996319   1.000000  0.694581  0.819767\n",
      "other_infrastructure    0.989075   0.998141  0.745833  0.853736\n",
      "weather_related         0.964790   0.991567  0.877332  0.930958\n",
      "floods                  0.982009   0.998073  0.774869  0.872421\n",
      "storm                   0.982009   0.991460  0.798487  0.884571\n",
      "fire                    0.996437   1.000000  0.640719  0.781022\n",
      "earthquake              0.977734   0.987844  0.772008  0.866690\n",
      "cold                    0.994241   1.000000  0.693038  0.818692\n",
      "other_weather           0.988006   0.996947  0.765533  0.866048\n",
      "direct_report           0.969778   0.994300  0.849878  0.916434\n"
     ]
    }
   ],
   "source": [
    "# Calculate evaluation metrics for training set\n",
    "y_train_pred = pipeline.predict(X_train)\n",
    "col_names = list(y.columns.values)\n",
    "\n",
    "print(get_eval_metrics(np.array(y_train), y_train_pred, col_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model():\n",
    "    pipeline = Pipeline([\n",
    "        ('vect', CountVectorizer(tokenizer=tokenize)),\n",
    "        ('tfidf', TfidfTransformer()),\n",
    "        ('clf', MultiOutputClassifier(RandomForestClassifier()))\n",
    "        ])\n",
    "    \n",
    "    parameters = {'vect__min_df': [1, 5],\n",
    "              'tfidf__use_idf':[True, False],\n",
    "              'clf__estimator__n_estimators':[10, 25], \n",
    "              'clf__estimator__min_samples_split':[2, 5, 10]}    \n",
    "   \n",
    "    cv = GridSearchCV(pipeline, param_grid = parameters, verbose = 2)\n",
    "\n",
    "    return cv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#previous parameter tryouts\n",
    "#  parameters = {\n",
    "  #      'vect__ngram_range': ((1, 1), (1, 2)),\n",
    "  #      'clf__estimator__min_samples_split': [2, ],\n",
    "  #      'vect__max_df': (0.5, 0.75, 1.0)\n",
    "   # }\n",
    "   # parameters = {\n",
    "   #     'vect__ngram_range': ((1, 1), (1, 2)),\n",
    "   #     'vect__max_df': (0.5, 0.75, 1.0),\n",
    "   #     'vect__max_features': (None, 5000, 10000),\n",
    "   #     'tfidf__use_idf': (True, False),\n",
    "   # }\n",
    "   # cv = GridSearchCV(pipeline, param_grid=parameters)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Building the model and assessing the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=None, error_score='raise',\n",
       "       estimator=Pipeline(memory=None,\n",
       "     steps=[('vect', CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "        ngram_range=(1, 1), preprocessor=None, stop_words=None,\n",
       "        strip...oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False),\n",
       "           n_jobs=1))]),\n",
       "       fit_params=None, iid=True, n_jobs=1,\n",
       "       param_grid={'vect__min_df': [1, 5], 'tfidf__use_idf': [True, False], 'clf__estimator__n_estimators': [10, 25], 'clf__estimator__min_samples_split': [2, 5, 10]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring=None, verbose=2)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = build_model()\n",
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Build model - first version\n",
    "Below is the first pipeline build, before adding MultiOutput and Grid search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model_old():   \n",
    "  \n",
    "    pipeline = Pipeline([\n",
    "        ('vect', CountVectorizer(tokenizer=tokenize)),\n",
    "        ('tfidf', TfidfTransformer()),\n",
    "        ('clf', RandomForestClassifier())\n",
    "    ])\n",
    "    \n",
    "    return pipeline    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_old = build_model_old()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "     steps=[('vect', CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "        ngram_range=(1, 1), preprocessor=None, stop_words=None,\n",
       "        strip...n_jobs=1,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False))])"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_old"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Train pipeline\n",
    "- Split data into train and test sets\n",
    "- Train pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Splitting the data\n",
    "Train and test sets are established by using the train_test_split method, imported from sklearn models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train and test datasets\n",
    "'Train_test_split' is used to establish the train and test datasets for X and y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state = 1)\n",
    "np.random.seed(9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fitting the model\n",
    "The model from build_data is fitted to the train datasets.\n",
    "This step is very time-consuming, taking ca 1 full hour to complete for this version "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "     steps=[('vect', CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "        ngram_range=(1, 1), preprocessor=None, stop_words=None,\n",
       "        strip...n_jobs=1,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False))])"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_old.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluation metrics\n",
    "Below is evaluation metrics. As I was struggling to debug my initial metrics (finally found I had to specify ''.values').\n",
    "\n",
    "I am (grateful for finding this setup on GitHub. I managed to fix my first metrics eventually, but kept both in the Notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_eval_metrics(actual, predicted, col_names):\n",
    "    \"\"\"Calculate evaluation metrics for ML model\n",
    "    \n",
    "    Args:\n",
    "    actual: array. Array containing actual labels.\n",
    "    predicted: array. Array containing predicted labels.\n",
    "    col_names: list of strings. List containing names for each of the predicted fields.\n",
    "       \n",
    "    Returns:\n",
    "    metrics_df: dataframe. Dataframe containing the accuracy, precision, recall \n",
    "    and f1 score for a given set of actual and predicted labels.\n",
    "    \"\"\"\n",
    "    metrics = []\n",
    "    \n",
    "    # Calculate evaluation metrics for each set of labels\n",
    "    for i in range(len(col_names)):\n",
    "        accuracy = accuracy_score(actual[:, i], predicted[:, i])\n",
    "        precision = precision_score(actual[:, i], predicted[:, i])\n",
    "        recall = recall_score(actual[:, i], predicted[:, i])\n",
    "        f1 = f1_score(actual[:, i], predicted[:, i])\n",
    "        \n",
    "        metrics.append([accuracy, precision, recall, f1])\n",
    "    \n",
    "    # Create dataframe containing metrics\n",
    "    metrics = np.array(metrics)\n",
    "    metrics_df = pd.DataFrame(data = metrics, index = col_names, columns = ['Accuracy', 'Precision', 'Recall', 'F1'])\n",
    "      \n",
    "    return metrics_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "related                   0.759619\n",
       "request                   0.173762\n",
       "offer                     0.004409\n",
       "aid_related               0.417038\n",
       "medical_help              0.079934\n",
       "medical_products          0.050677\n",
       "search_and_rescue         0.027031\n",
       "security                  0.018213\n",
       "military                  0.034378\n",
       "water                     0.065194\n",
       "food                      0.111997\n",
       "shelter                   0.090221\n",
       "clothing                  0.014918\n",
       "money                     0.022533\n",
       "missing_people            0.010777\n",
       "refugees                  0.033443\n",
       "death                     0.044621\n",
       "other_aid                 0.131902\n",
       "infrastructure_related    0.063903\n",
       "transport                 0.046090\n",
       "buildings                 0.051256\n",
       "electricity               0.020440\n",
       "tools                     0.006234\n",
       "hospitals                 0.010509\n",
       "shops                     0.004409\n",
       "aid_centers               0.011934\n",
       "other_infrastructure      0.043240\n",
       "weather_related           0.269861\n",
       "floods                    0.079890\n",
       "storm                     0.087326\n",
       "fire                      0.010153\n",
       "earthquake                0.091557\n",
       "cold                      0.018970\n",
       "other_weather             0.050989\n",
       "direct_report             0.195271\n",
       "dtype: float64"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculation the proportion of each column that have label == 1\n",
    "y.sum()/len(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                        Accuracy  Precision    Recall        F1\n",
      "related                 0.984266   0.983719  0.995782  0.989714\n",
      "request                 0.974825   0.994380  0.857984  0.921160\n",
      "offer                   0.998575   1.000000  0.692308  0.818182\n",
      "aid_related             0.970194   0.994973  0.933000  0.962990\n",
      "medical_help            0.979694   0.997998  0.745699  0.853596\n",
      "medical_products        0.986166   1.000000  0.728438  0.842886\n",
      "search_and_rescue       0.991984   0.993671  0.702461  0.823067\n",
      "security                0.995309   0.995349  0.732877  0.844181\n",
      "military                0.990381   0.995238  0.723183  0.837675\n",
      "water                   0.983850   0.997558  0.751610  0.857293\n",
      "food                    0.975656   0.995924  0.783957  0.877319\n",
      "shelter                 0.978803   0.998253  0.763017  0.864926\n",
      "clothing                0.995962   0.988827  0.728395  0.838863\n",
      "money                   0.994359   0.996255  0.738889  0.848485\n",
      "missing_people          0.996972   1.000000  0.716667  0.834951\n",
      "refugees                0.990381   0.992574  0.716071  0.831950\n",
      "death                   0.988362   0.998192  0.738956  0.849231\n",
      "other_aid               0.969719   0.991995  0.777678  0.871859\n",
      "infrastructure_related  0.982247   0.998708  0.721755  0.837940\n",
      "transport               0.986759   0.994690  0.718670  0.834447\n",
      "buildings               0.985453   0.998410  0.720183  0.836775\n",
      "electricity             0.994062   1.000000  0.715909  0.834437\n",
      "tools                   0.998397   1.000000  0.737864  0.849162\n",
      "hospitals               0.997328   1.000000  0.744318  0.853420\n",
      "shops                   0.998516   1.000000  0.666667  0.800000\n",
      "aid_centers             0.996319   1.000000  0.694581  0.819767\n",
      "other_infrastructure    0.989075   0.998141  0.745833  0.853736\n",
      "weather_related         0.964790   0.991567  0.877332  0.930958\n",
      "floods                  0.982009   0.998073  0.774869  0.872421\n",
      "storm                   0.982009   0.991460  0.798487  0.884571\n",
      "fire                    0.996437   1.000000  0.640719  0.781022\n",
      "earthquake              0.977734   0.987844  0.772008  0.866690\n",
      "cold                    0.994241   1.000000  0.693038  0.818692\n",
      "other_weather           0.988006   0.996947  0.765533  0.866048\n",
      "direct_report           0.969778   0.994300  0.849878  0.916434\n"
     ]
    }
   ],
   "source": [
    "# Calculate evaluation metrics for training set\n",
    "y_train_pred = pipeline.predict(X_train)\n",
    "col_names = list(y.columns.values)\n",
    "\n",
    "print(get_eval_metrics(np.array(y_train), y_train_pred, col_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                        Accuracy  Precision    Recall        F1\n",
      "related                 0.959268   0.949677  0.999375  0.973893\n",
      "request                 0.965622   0.999135  0.800139  0.888632\n",
      "offer                   0.996081   1.000000  0.153846  0.266667\n",
      "aid_related             0.986759   0.997504  0.970571  0.983853\n",
      "medical_help            0.965028   0.997340  0.560957  0.718047\n",
      "medical_products        0.974944   0.997717  0.509324  0.674383\n",
      "search_and_rescue       0.984325   1.000000  0.409396  0.580952\n",
      "security                0.988303   1.000000  0.325342  0.490956\n",
      "military                0.982128   0.996416  0.480969  0.648775\n",
      "water                   0.967640   1.000000  0.498620  0.665439\n",
      "food                    0.951550   0.999053  0.564171  0.721121\n",
      "shelter                 0.962059   0.998839  0.574099  0.729123\n",
      "clothing                0.988897   1.000000  0.230453  0.374582\n",
      "money                   0.986166   1.000000  0.352778  0.521561\n",
      "missing_people          0.991866   1.000000  0.238889  0.385650\n",
      "refugees                0.981534   0.996016  0.446429  0.616523\n",
      "death                   0.978387   1.000000  0.512718  0.677876\n",
      "other_aid               0.949353   0.995683  0.620350  0.764430\n",
      "infrastructure_related  0.971915   1.000000  0.558357  0.716597\n",
      "transport               0.979040   1.000000  0.548593  0.708505\n",
      "buildings               0.975953   1.000000  0.535550  0.697535\n",
      "electricity             0.987056   1.000000  0.380682  0.551440\n",
      "tools                   0.995012   1.000000  0.184466  0.311475\n",
      "hospitals               0.992222   1.000000  0.255682  0.407240\n",
      "shops                   0.996259   1.000000  0.160000  0.275862\n",
      "aid_centers             0.991153   1.000000  0.266010  0.420233\n",
      "other_infrastructure    0.980287   0.997436  0.540278  0.700901\n",
      "weather_related         0.960931   0.994671  0.860215  0.922570\n",
      "floods                  0.971440   0.998834  0.640987  0.780866\n",
      "storm                   0.969006   0.994692  0.644429  0.782137\n",
      "fire                    0.992816   0.979167  0.281437  0.437209\n",
      "earthquake              0.959387   0.995570  0.569348  0.724416\n",
      "cold                    0.988719   1.000000  0.398734  0.570136\n",
      "other_weather           0.977675   1.000000  0.559203  0.717293\n",
      "direct_report           0.964375   0.999256  0.817905  0.899531\n"
     ]
    }
   ],
   "source": [
    "# Calculate evaluation metrics for training set\n",
    "y_train_pred = model.predict(X_train)\n",
    "col_names = list(y.columns.values)\n",
    "\n",
    "print(get_eval_metrics(np.array(y_train), y_train_pred, col_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                        Accuracy  Precision    Recall        F1\n",
      "related                 0.988778   0.986952  0.998438  0.992662\n",
      "request                 0.978981   0.997252  0.879806  0.934855\n",
      "offer                   0.998575   1.000000  0.692308  0.818182\n",
      "aid_related             0.970372   0.994975  0.933429  0.963220\n",
      "medical_help            0.979100   0.998987  0.737472  0.848537\n",
      "medical_products        0.986819   1.000000  0.741259  0.851406\n",
      "search_and_rescue       0.992341   1.000000  0.711409  0.831373\n",
      "security                0.995309   0.995349  0.732877  0.844181\n",
      "military                0.990856   0.997653  0.735294  0.846614\n",
      "water                   0.984384   1.000000  0.758050  0.862376\n",
      "food                    0.975656   0.998634  0.781818  0.877025\n",
      "shelter                 0.980287   0.998291  0.779706  0.875562\n",
      "clothing                0.996497   0.994624  0.761317  0.862471\n",
      "money                   0.994241   1.000000  0.730556  0.844302\n",
      "missing_people          0.997031   1.000000  0.722222  0.838710\n",
      "refugees                0.990856   0.995122  0.728571  0.841237\n",
      "death                   0.988303   1.000000  0.736278  0.848111\n",
      "other_aid               0.972034   0.995495  0.792470  0.882456\n",
      "infrastructure_related  0.982959   0.998728  0.732960  0.845450\n",
      "transport               0.986759   1.000000  0.714834  0.833706\n",
      "buildings               0.985512   0.996835  0.722477  0.837766\n",
      "electricity             0.994122   0.996078  0.721591  0.836903\n",
      "tools                   0.998397   1.000000  0.737864  0.849162\n",
      "hospitals               0.997684   1.000000  0.778409  0.875399\n",
      "shops                   0.998575   1.000000  0.680000  0.809524\n",
      "aid_centers             0.996675   1.000000  0.724138  0.840000\n",
      "other_infrastructure    0.989906   1.000000  0.763889  0.866142\n",
      "weather_related         0.967284   0.995547  0.883037  0.935923\n",
      "floods                  0.981475   0.998056  0.768138  0.868132\n",
      "storm                   0.983197   0.995766  0.808803  0.892600\n",
      "fire                    0.996437   1.000000  0.640719  0.781022\n",
      "earthquake              0.979872   0.995208  0.789107  0.880254\n",
      "cold                    0.994716   1.000000  0.718354  0.836096\n",
      "other_weather           0.987828   0.998462  0.760844  0.863606\n",
      "direct_report           0.971084   0.996803  0.854446  0.920151\n"
     ]
    }
   ],
   "source": [
    "# Calculate evaluation metrics for training set\n",
    "y_test_pred = pipeline.predict(X_test)\n",
    "col_names = list(y.columns.values)\n",
    "\n",
    "print(get_eval_metrics(np.array(y_train), y_train_pred, col_names))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Testing the simple standalone predict and looking at the results "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = pipeline.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 0, 0, ..., 0, 0, 0],\n",
       "       [1, 0, 0, ..., 0, 0, 0],\n",
       "       [1, 0, 0, ..., 0, 0, 0],\n",
       "       ..., \n",
       "       [1, 0, 0, ..., 0, 0, 0],\n",
       "       [1, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0]])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Display result\n",
    "The display_result function was used for the model before MultiOutputClassifier was added \n",
    "It cannot be used for MultiOutput"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_results(y_test, y_pred):\n",
    "    labels = np.unique(y_pred)\n",
    "    confusion_mat = confusion_matrix(y_test, y_pred, labels=labels)\n",
    "    accuracy = (y_pred == y_test).mean()\n",
    "\n",
    "    print(\"Labels:\", labels)\n",
    "    print(\"Confusion Matrix:\\n\", confusion_mat)\n",
    "    print(\"Accuracy:\", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display_results(y_test, y_pred)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dataframe versions of y_test and y_pred\n",
    "Need to make these sets dataframes to be usen in the evaluation function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_df= pd.DataFrame(data=y_test)\n",
    "y_pred_df= pd.DataFrame(data=y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Test your model\n",
    "Report the f1 score, precision and recall for each output category of the dataset. You can do this by iterating through the columns and calling sklearn's `classification_report` on each."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy scores for each category\n",
      "\n",
      "*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-\n",
      "Category: related \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.38      0.02      0.04      1359\n",
      "          1       0.76      0.99      0.86      4255\n",
      "\n",
      "avg / total       0.67      0.75      0.66      5614\n",
      "\n",
      "Category: request \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.82      1.00      0.90      4599\n",
      "          1       0.44      0.01      0.02      1015\n",
      "\n",
      "avg / total       0.75      0.82      0.74      5614\n",
      "\n",
      "Category: offer \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      1.00      1.00      5593\n",
      "          1       0.00      0.00      0.00        21\n",
      "\n",
      "avg / total       0.99      1.00      0.99      5614\n",
      "\n",
      "Category: aid_related \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.59      0.86      0.70      3249\n",
      "          1       0.47      0.17      0.25      2365\n",
      "\n",
      "avg / total       0.54      0.57      0.51      5614\n",
      "\n",
      "Category: medical_help \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.92      1.00      0.96      5156\n",
      "          1       0.00      0.00      0.00       458\n",
      "\n",
      "avg / total       0.84      0.92      0.88      5614\n",
      "\n",
      "Category: medical_products \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.95      1.00      0.97      5334\n",
      "          1       0.06      0.00      0.01       280\n",
      "\n",
      "avg / total       0.91      0.95      0.92      5614\n",
      "\n",
      "Category: search_and_rescue \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.97      1.00      0.99      5454\n",
      "          1       0.00      0.00      0.00       160\n",
      "\n",
      "avg / total       0.94      0.97      0.96      5614\n",
      "\n",
      "Category: security \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.98      1.00      0.99      5497\n",
      "          1       0.00      0.00      0.00       117\n",
      "\n",
      "avg / total       0.96      0.98      0.97      5614\n",
      "\n",
      "Category: military \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.97      1.00      0.98      5420\n",
      "          1       1.00      0.01      0.02       194\n",
      "\n",
      "avg / total       0.97      0.97      0.95      5614\n",
      "\n",
      "Category: water \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.93      1.00      0.96      5237\n",
      "          1       0.00      0.00      0.00       377\n",
      "\n",
      "avg / total       0.87      0.93      0.90      5614\n",
      "\n",
      "Category: food \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.89      1.00      0.94      4969\n",
      "          1       0.14      0.00      0.01       645\n",
      "\n",
      "avg / total       0.80      0.88      0.83      5614\n",
      "\n",
      "Category: shelter \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.91      0.99      0.95      5086\n",
      "          1       0.04      0.00      0.00       528\n",
      "\n",
      "avg / total       0.82      0.90      0.86      5614\n",
      "\n",
      "Category: clothing \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.98      1.00      0.99      5522\n",
      "          1       0.00      0.00      0.00        92\n",
      "\n",
      "avg / total       0.97      0.98      0.98      5614\n",
      "\n",
      "Category: money \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.97      1.00      0.99      5468\n",
      "          1       0.00      0.00      0.00       146\n",
      "\n",
      "avg / total       0.95      0.97      0.96      5614\n",
      "\n",
      "Category: missing_people \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.99      1.00      0.99      5552\n",
      "          1       0.00      0.00      0.00        62\n",
      "\n",
      "avg / total       0.98      0.99      0.98      5614\n",
      "\n",
      "Category: refugees \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.97      1.00      0.98      5423\n",
      "          1       0.00      0.00      0.00       191\n",
      "\n",
      "avg / total       0.93      0.97      0.95      5614\n",
      "\n",
      "Category: death \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.95      1.00      0.98      5359\n",
      "          1       0.11      0.00      0.01       255\n",
      "\n",
      "avg / total       0.92      0.95      0.93      5614\n",
      "\n",
      "Category: other_aid \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.87      0.99      0.93      4883\n",
      "          1       0.07      0.00      0.01       731\n",
      "\n",
      "avg / total       0.77      0.87      0.81      5614\n",
      "\n",
      "Category: infrastructure_related \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.94      1.00      0.97      5250\n",
      "          1       0.15      0.01      0.01       364\n",
      "\n",
      "avg / total       0.88      0.93      0.90      5614\n",
      "\n",
      "Category: transport \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.95      1.00      0.98      5361\n",
      "          1       0.00      0.00      0.00       253\n",
      "\n",
      "avg / total       0.91      0.95      0.93      5614\n",
      "\n",
      "Category: buildings \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.95      1.00      0.97      5335\n",
      "          1       0.07      0.00      0.01       279\n",
      "\n",
      "avg / total       0.91      0.95      0.93      5614\n",
      "\n",
      "Category: electricity \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.98      1.00      0.99      5507\n",
      "          1       0.00      0.00      0.00       107\n",
      "\n",
      "avg / total       0.96      0.98      0.97      5614\n",
      "\n",
      "Category: tools \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.99      1.00      1.00      5577\n",
      "          1       0.00      0.00      0.00        37\n",
      "\n",
      "avg / total       0.99      0.99      0.99      5614\n",
      "\n",
      "Category: hospitals \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.99      1.00      0.99      5554\n",
      "          1       0.00      0.00      0.00        60\n",
      "\n",
      "avg / total       0.98      0.99      0.98      5614\n",
      "\n",
      "Category: shops \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      1.00      1.00      5590\n",
      "          1       0.00      0.00      0.00        24\n",
      "\n",
      "avg / total       0.99      1.00      0.99      5614\n",
      "\n",
      "Category: aid_centers \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.99      1.00      0.99      5549\n",
      "          1       0.00      0.00      0.00        65\n",
      "\n",
      "avg / total       0.98      0.99      0.98      5614\n",
      "\n",
      "Category: other_infrastructure \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.96      1.00      0.98      5363\n",
      "          1       0.14      0.00      0.01       251\n",
      "\n",
      "avg / total       0.92      0.95      0.93      5614\n",
      "\n",
      "Category: weather_related \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.75      0.96      0.85      4111\n",
      "          1       0.59      0.14      0.23      1503\n",
      "\n",
      "avg / total       0.71      0.74      0.68      5614\n",
      "\n",
      "Category: floods \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.92      1.00      0.96      5157\n",
      "          1       0.25      0.00      0.00       457\n",
      "\n",
      "avg / total       0.86      0.92      0.88      5614\n",
      "\n",
      "Category: storm \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.91      1.00      0.95      5107\n",
      "          1       0.36      0.02      0.03       507\n",
      "\n",
      "avg / total       0.86      0.91      0.87      5614\n",
      "\n",
      "Category: fire \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.99      1.00      0.99      5553\n",
      "          1       0.00      0.00      0.00        61\n",
      "\n",
      "avg / total       0.98      0.99      0.98      5614\n",
      "\n",
      "Category: earthquake \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.92      1.00      0.96      5137\n",
      "          1       0.40      0.01      0.02       477\n",
      "\n",
      "avg / total       0.87      0.91      0.88      5614\n",
      "\n",
      "Category: cold \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.98      1.00      0.99      5504\n",
      "          1       0.00      0.00      0.00       110\n",
      "\n",
      "avg / total       0.96      0.98      0.97      5614\n",
      "\n",
      "Category: other_weather \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.95      1.00      0.97      5322\n",
      "          1       0.00      0.00      0.00       292\n",
      "\n",
      "avg / total       0.90      0.94      0.92      5614\n",
      "\n",
      "Category: direct_report \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.80      0.99      0.89      4513\n",
      "          1       0.33      0.01      0.02      1101\n",
      "\n",
      "avg / total       0.71      0.80      0.72      5614\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy scores for each category\\n\")\n",
    "print(\"*-\" * 30)\n",
    "\n",
    "for i in range(35):\n",
    "    print(\"Category:\", category_names[i],\"\\n\", classification_report(y_test_df.values[:, i], y_pred_df.values[:, i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model, X_test, y_test, category_names):\n",
    "    \"\"\"\n",
    "    Evaluates the trained model by predicting on test data\n",
    "    The classification report prints output accuracy, precision and recall for all categories\n",
    "    \"\"\"\n",
    "    y_pred = model.predict(X_test)\n",
    "    for i in range(0, len(category_names)):\n",
    "        print(\"Category:\", category_names[i])\n",
    "        print(classification_report(y_test_df.values[:,i], y_pred_df.values[:,i]))      \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#evaluate_model(model_old, X_test, y_test, category_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "#y_train_pred = model.predict(X_train)\n",
    "#col_names = list(y.columns.values)\n",
    "\n",
    "#print(get_eval_metrics(np.array(y_train), y_train_pred, col_names))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Improve your model\n",
    "Use grid search to find better parameters. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Grid search was introduced in the pipeline and tested. \n",
    "The code is updated and the latest version is in above cells"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. Test your model\n",
    "Show the accuracy, precision, and recall of the tuned model.  \n",
    "\n",
    "Since this project focuses on code quality, process, and  pipelines, there is no minimum performance metric needed to pass. However, make sure to fine tune your models for accuracy, precision and recall to make your project stand out - especially for your portfolio!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Category: id\n",
      "'Accuracy:  0.754542215889\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.38      0.02      0.04      1359\n",
      "          1       0.76      0.99      0.86      4255\n",
      "\n",
      "avg / total       0.67      0.75      0.66      5614\n",
      "\n",
      "Category: message\n",
      "'Accuracy:  0.818667616673\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.82      1.00      0.90      4599\n",
      "          1       0.44      0.01      0.02      1015\n",
      "\n",
      "avg / total       0.75      0.82      0.74      5614\n",
      "\n",
      "Category: original\n",
      "'Accuracy:  0.996259351621\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      1.00      1.00      5593\n",
      "          1       0.00      0.00      0.00        21\n",
      "\n",
      "avg / total       0.99      1.00      0.99      5614\n",
      "\n",
      "Category: genre\n",
      "'Accuracy:  0.570894193089\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.59      0.86      0.70      3249\n",
      "          1       0.47      0.17      0.25      2365\n",
      "\n",
      "avg / total       0.54      0.57      0.51      5614\n",
      "\n",
      "Category: related\n",
      "'Accuracy:  0.917171357321\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.92      1.00      0.96      5156\n",
      "          1       0.00      0.00      0.00       458\n",
      "\n",
      "avg / total       0.84      0.92      0.88      5614\n",
      "\n",
      "Category: request\n",
      "'Accuracy:  0.947274670467\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.95      1.00      0.97      5334\n",
      "          1       0.06      0.00      0.01       280\n",
      "\n",
      "avg / total       0.91      0.95      0.92      5614\n",
      "\n",
      "Category: offer\n",
      "'Accuracy:  0.971143569647\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.97      1.00      0.99      5454\n",
      "          1       0.00      0.00      0.00       160\n",
      "\n",
      "avg / total       0.94      0.97      0.96      5614\n",
      "\n",
      "Category: aid_related\n",
      "'Accuracy:  0.979159244745\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.98      1.00      0.99      5497\n",
      "          1       0.00      0.00      0.00       117\n",
      "\n",
      "avg / total       0.96      0.98      0.97      5614\n",
      "\n",
      "Category: medical_help\n",
      "'Accuracy:  0.965799786249\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.97      1.00      0.98      5420\n",
      "          1       1.00      0.01      0.02       194\n",
      "\n",
      "avg / total       0.97      0.97      0.95      5614\n",
      "\n",
      "Category: medical_products\n",
      "'Accuracy:  0.931243320271\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.93      1.00      0.96      5237\n",
      "          1       0.00      0.00      0.00       377\n",
      "\n",
      "avg / total       0.87      0.93      0.90      5614\n",
      "\n",
      "Category: search_and_rescue\n",
      "'Accuracy:  0.883327395796\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.89      1.00      0.94      4969\n",
      "          1       0.14      0.00      0.01       645\n",
      "\n",
      "avg / total       0.80      0.88      0.83      5614\n",
      "\n",
      "Category: security\n",
      "'Accuracy:  0.901318133238\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.91      0.99      0.95      5086\n",
      "          1       0.04      0.00      0.00       528\n",
      "\n",
      "avg / total       0.82      0.90      0.86      5614\n",
      "\n",
      "Category: military\n",
      "'Accuracy:  0.983612397577\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.98      1.00      0.99      5522\n",
      "          1       0.00      0.00      0.00        92\n",
      "\n",
      "avg / total       0.97      0.98      0.98      5614\n",
      "\n",
      "Category: water\n",
      "'Accuracy:  0.97399358746\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.97      1.00      0.99      5468\n",
      "          1       0.00      0.00      0.00       146\n",
      "\n",
      "avg / total       0.95      0.97      0.96      5614\n",
      "\n",
      "Category: food\n",
      "'Accuracy:  0.988956180976\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.99      1.00      0.99      5552\n",
      "          1       0.00      0.00      0.00        62\n",
      "\n",
      "avg / total       0.98      0.99      0.98      5614\n",
      "\n",
      "Category: shelter\n",
      "'Accuracy:  0.965799786249\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.97      1.00      0.98      5423\n",
      "          1       0.00      0.00      0.00       191\n",
      "\n",
      "avg / total       0.93      0.97      0.95      5614\n",
      "\n",
      "Category: clothing\n",
      "'Accuracy:  0.953330958318\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.95      1.00      0.98      5359\n",
      "          1       0.11      0.00      0.01       255\n",
      "\n",
      "avg / total       0.92      0.95      0.93      5614\n",
      "\n",
      "Category: money\n",
      "'Accuracy:  0.865514784467\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.87      0.99      0.93      4883\n",
      "          1       0.07      0.00      0.01       731\n",
      "\n",
      "avg / total       0.77      0.87      0.81      5614\n",
      "\n",
      "Category: missing_people\n",
      "'Accuracy:  0.933558959743\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.94      1.00      0.97      5250\n",
      "          1       0.15      0.01      0.01       364\n",
      "\n",
      "avg / total       0.88      0.93      0.90      5614\n",
      "\n",
      "Category: refugees\n",
      "'Accuracy:  0.953509084432\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.95      1.00      0.98      5361\n",
      "          1       0.00      0.00      0.00       253\n",
      "\n",
      "avg / total       0.91      0.95      0.93      5614\n",
      "\n",
      "Category: death\n",
      "'Accuracy:  0.948165301033\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.95      1.00      0.97      5335\n",
      "          1       0.07      0.00      0.01       279\n",
      "\n",
      "avg / total       0.91      0.95      0.93      5614\n",
      "\n",
      "Category: other_aid\n",
      "'Accuracy:  0.980762379765\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.98      1.00      0.99      5507\n",
      "          1       0.00      0.00      0.00       107\n",
      "\n",
      "avg / total       0.96      0.98      0.97      5614\n",
      "\n",
      "Category: infrastructure_related\n",
      "'Accuracy:  0.993409333808\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.99      1.00      1.00      5577\n",
      "          1       0.00      0.00      0.00        37\n",
      "\n",
      "avg / total       0.99      0.99      0.99      5614\n",
      "\n",
      "Category: transport\n",
      "'Accuracy:  0.989312433203\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.99      1.00      0.99      5554\n",
      "          1       0.00      0.00      0.00        60\n",
      "\n",
      "avg / total       0.98      0.99      0.98      5614\n",
      "\n",
      "Category: buildings\n",
      "'Accuracy:  0.995724973281\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      1.00      1.00      5590\n",
      "          1       0.00      0.00      0.00        24\n",
      "\n",
      "avg / total       0.99      1.00      0.99      5614\n",
      "\n",
      "Category: electricity\n",
      "'Accuracy:  0.988421802636\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.99      1.00      0.99      5549\n",
      "          1       0.00      0.00      0.00        65\n",
      "\n",
      "avg / total       0.98      0.99      0.98      5614\n",
      "\n",
      "Category: tools\n",
      "'Accuracy:  0.954399714998\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.96      1.00      0.98      5363\n",
      "          1       0.14      0.00      0.01       251\n",
      "\n",
      "avg / total       0.92      0.95      0.93      5614\n",
      "\n",
      "Category: hospitals\n",
      "'Accuracy:  0.744032775205\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.75      0.96      0.85      4111\n",
      "          1       0.59      0.14      0.23      1503\n",
      "\n",
      "avg / total       0.71      0.74      0.68      5614\n",
      "\n",
      "Category: shops\n",
      "'Accuracy:  0.918240114001\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.92      1.00      0.96      5157\n",
      "          1       0.25      0.00      0.00       457\n",
      "\n",
      "avg / total       0.86      0.92      0.88      5614\n",
      "\n",
      "Category: aid_centers\n",
      "'Accuracy:  0.90844317777\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.91      1.00      0.95      5107\n",
      "          1       0.36      0.02      0.03       507\n",
      "\n",
      "avg / total       0.86      0.91      0.87      5614\n",
      "\n",
      "Category: other_infrastructure\n",
      "'Accuracy:  0.989134307089\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.99      1.00      0.99      5553\n",
      "          1       0.00      0.00      0.00        61\n",
      "\n",
      "avg / total       0.98      0.99      0.98      5614\n",
      "\n",
      "Category: weather_related\n",
      "'Accuracy:  0.914499465622\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.92      1.00      0.96      5137\n",
      "          1       0.40      0.01      0.02       477\n",
      "\n",
      "avg / total       0.87      0.91      0.88      5614\n",
      "\n",
      "Category: floods\n",
      "'Accuracy:  0.979871749198\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.98      1.00      0.99      5504\n",
      "          1       0.00      0.00      0.00       110\n",
      "\n",
      "avg / total       0.96      0.98      0.97      5614\n",
      "\n",
      "Category: storm\n",
      "'Accuracy:  0.944602778767\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.95      1.00      0.97      5322\n",
      "          1       0.00      0.00      0.00       292\n",
      "\n",
      "avg / total       0.90      0.94      0.92      5614\n",
      "\n",
      "Category: fire\n",
      "'Accuracy:  0.801567509797\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.80      0.99      0.89      4513\n",
      "          1       0.33      0.01      0.02      1101\n",
      "\n",
      "avg / total       0.71      0.80      0.72      5614\n",
      "\n",
      "Category: earthquake\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "index 35 is out of bounds for axis 1 with size 35",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-165-9d97dd94609d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcategory_names\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Category:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcategory_names\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"'Accuracy: \"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccuracy_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclassification_report\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: index 35 is out of bounds for axis 1 with size 35"
     ]
    }
   ],
   "source": [
    "#y_pred = model.predict(X_test)\n",
    "for i in range(0, len(category_names)):\n",
    "        print(\"Category:\", category_names[i])\n",
    "        print(\"'Accuracy: \", accuracy_score(y_test_df.values[:,i], y_pred_df.values[:,i]))\n",
    "        print(classification_report(y_test_df.values[:,i], y_pred_df.values[:,i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#y_pred_old = model_old.predict(X_test)\n",
    "#print('Accuracy:', accuracy_score(y_test, y_pred_old))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8. Try improving your model further. Here are a few ideas:\n",
    "* try other machine learning algorithms\n",
    "* add other features besides the TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9. Export your model as a pickle file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Saving model as pickle file - 'Model'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_model1(model, model_filepath):\n",
    "    file_Name = 'model_filepath'   \n",
    "    fileObject = open(file_Name,'wb')    \n",
    "    pickle.dump(model,fileObject)    \n",
    "    fileObject.close()    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_model1(model, 'mymodel.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_model2(model, model_filepath):\n",
    "    pickle.dump(model, open(model_filepath, \"wb\"))  \n",
    "    print('model saved in:', model_filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model saved in: modelnew2.pkl\n"
     ]
    }
   ],
   "source": [
    "save_model2(model, 'modelnew2.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_model3(model, model_filepath):\n",
    "    joblib.dump(model, model_filepath)\n",
    "    print('joblib model saved in:', model_filepath)\n",
    "    joblib.dump(model, 'joblib_model.pkl')\n",
    "    print('joblib model saved in:', 'joblib_model.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "joblib model saved in: modelnew.pkl\n",
      "joblib model saved in: joblib_model.pkl\n"
     ]
    }
   ],
   "source": [
    "save_model3(model, 'modelnew.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "pkl_filename = \"pickle_model.pkl\"  \n",
    "with open(pkl_filename, 'wb') as file:  \n",
    "    pickle.dump(model, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load from file\n",
    "with open(pkl_filename, 'rb') as file:  \n",
    "    pickle_model = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=None, error_score='raise',\n",
       "       estimator=Pipeline(memory=None,\n",
       "     steps=[('vect', CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "        ngram_range=(1, 1), preprocessor=None, stop_words=None,\n",
       "        strip...oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False),\n",
       "           n_jobs=1))]),\n",
       "       fit_params=None, iid=True, n_jobs=1,\n",
       "       param_grid={'vect__ngram_range': ((1, 1), (1, 2)), 'clf__estimator__min_samples_split': [2, 4], 'vect__max_df': (0.5, 0.75, 1.0)},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring=None, verbose=0)"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pickle_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test score: 14.61 %\n"
     ]
    }
   ],
   "source": [
    "score = pipeline.score(X_test, y_test)  \n",
    "print(\"Test score: {0:.2f} %\".format(100 * score)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test score: 14.67 %\n"
     ]
    }
   ],
   "source": [
    "score = pickle_model.score(X_test, y_test)  \n",
    "print(\"Test score: {0:.2f} %\".format(100 * score))  \n",
    "#Ypredict = pickle_model.predict(Xtest)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test score: 15.60 %\n"
     ]
    }
   ],
   "source": [
    "score = model.score(X_test, y_test)  \n",
    "print(\"Test score: {0:.2f} %\".format(100 * score)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['joblib_model.pkl']"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.externals import joblib\n",
    "# Save to file in the current working directory\n",
    "joblib_file = \"joblib_model.pkl\"  \n",
    "joblib.dump(model, joblib_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load from file\n",
    "#joblib_model = joblib.load(joblib_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model=joblib.load(newmodel.pkl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=None, error_score='raise',\n",
       "       estimator=Pipeline(memory=None,\n",
       "     steps=[('vect', CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "        ngram_range=(1, 1), preprocessor=None, stop_words=None,\n",
       "        strip...oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False),\n",
       "           n_jobs=1))]),\n",
       "       fit_params=None, iid=True, n_jobs=1,\n",
       "       param_grid={'vect__ngram_range': ((1, 1), (1, 2)), 'clf__estimator__min_samples_split': [2, 4], 'vect__max_df': (0.5, 0.75, 1.0)},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring=None, verbose=0)"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test score: 15.60 %\n"
     ]
    }
   ],
   "source": [
    "# Calculate the accuracy and predictions\n",
    "score = model.score(X_test, y_test)  \n",
    "print(\"Test score: {0:.2f} %\".format(100 * score)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "Ypredict = joblib_model.predict(X_test)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([['1', '0', '0', ..., '0', '0', '0'],\n",
       "       ['1', '0', '0', ..., '0', '0', '0'],\n",
       "       ['1', '0', '0', ..., '0', '0', '0'],\n",
       "       ..., \n",
       "       ['1', '0', '0', ..., '0', '0', '0'],\n",
       "       ['1', '0', '0', ..., '0', '0', '0'],\n",
       "       ['0', '0', '0', ..., '0', '0', '0']], dtype=object)"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Ypredict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "#evaluate_model(joblib_model, X_test, y_test, category_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading model from pickle file "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model(model_file):\n",
    "# we open the file for reading\n",
    "    fileObject = open('mymodel','rb')  \n",
    "    # load the object from the file into var modelX\n",
    "    model = pickle.load(fileObject)  \n",
    "    model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.externals import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['newmodel.pkl']"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filename = 'newmodel.pkl'\n",
    "joblib.dump(model, filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the model to disk\n",
    "filename = 'finalized_model.sav'\n",
    "joblib.dump(model, filename)\n",
    " \n",
    "# some time later...\n",
    " \n",
    "# load the model from disk\n",
    "loaded_model = joblib.load(filename)\n",
    "result = loaded_model.score(X_test, Y_test)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Use the load below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = joblib.load('newmodel.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=None, error_score='raise',\n",
       "       estimator=Pipeline(memory=None,\n",
       "     steps=[('vect', CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "        ngram_range=(1, 1), preprocessor=None, stop_words=None,\n",
       "        strip...oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False),\n",
       "           n_jobs=1))]),\n",
       "       fit_params=None, iid=True, n_jobs=1,\n",
       "       param_grid={'vect__min_df': [1, 5], 'tfidf__use_idf': [True, False], 'clf__estimator__n_estimators': [10, 25], 'clf__estimator__min_samples_split': [2, 5, 10]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring=None, verbose=2)"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10. Use this notebook to complete `train.py`\n",
    "Use the template file attached in the Resources folder to write a script that runs the steps above to create a database and export a model based on a new dataset specified by the user."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Putting all steps together\n",
    "Below is a main function with the steps needed to run the code, calling the functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    df, X, y, category_names = load_data()\n",
    "    clean_tokens= tokenize(text)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y)\n",
    "    model = build_model()\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    get_eval_metrics(actual, predicted, col_names):\n",
    "    evaluate_model(model, y_test, y_pred)\n",
    "    save_model(model, model_filepath)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Testing the main program stucture with main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Testing visuals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "genre\n",
       "direct    10646\n",
       "news       9468\n",
       "social     2342\n",
       "Name: message, dtype: int64"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "genre_counts = df.groupby('genre').count()['message']\n",
    "genre_names = list(genre_counts.index)\n",
    "genre_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "    # Show distribution of different category\n",
    "category = list(df.columns[4:])\n",
    "category_counts = []\n",
    "    for column_name in category:\n",
    "        category_counts.append(np.sum(df[column_name]))\n",
    "\n",
    "    # extract data exclude related\n",
    "categories = df.iloc[:,4:]\n",
    "categories_mean = categories.mean().sort_values(ascending=False)[1:11]\n",
    "categories_names = list(categories_mean.index)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[17058,\n",
       " 3902,\n",
       " 99,\n",
       " 9365,\n",
       " 1795,\n",
       " 1138,\n",
       " 607,\n",
       " 409,\n",
       " 772,\n",
       " 1464,\n",
       " 2515,\n",
       " 2026,\n",
       " 335,\n",
       " 506,\n",
       " 242,\n",
       " 751,\n",
       " 1002,\n",
       " 2962,\n",
       " 1435,\n",
       " 1035,\n",
       " 1151,\n",
       " 459,\n",
       " 140,\n",
       " 236,\n",
       " 99,\n",
       " 268,\n",
       " 971,\n",
       " 6060,\n",
       " 1794,\n",
       " 1961,\n",
       " 228,\n",
       " 2056,\n",
       " 426,\n",
       " 1145,\n",
       " 4385]"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "category_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "catcount_df = pd.DataFrame(catcounts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "categories = df.iloc[:, 4:]\n",
    "cat_names = list(categories)\n",
    "catcounts = [df[cat_name].value_counts for cat_name in cat_names]\n",
    "#catcount = categories.apply(lambda x: x.value_counts()).T.stack()\n",
    "#catcounts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "#catcount_df.head()\n",
    "#catcount_df.describe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "category = list(df.columns[4:])\n",
    "category_counts = []\n",
    "for column_name in category:\n",
    "    category_counts.append(np.sum(df[column_name]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#category_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "categories = df.iloc[:,4:]\n",
    "categories_mean = categories.mean().sort_values(ascending=False)[1:15]\n",
    "categories_names = list(categories_mean.index)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "aid_related               0.417038\n",
       "weather_related           0.269861\n",
       "direct_report             0.195271\n",
       "request                   0.173762\n",
       "other_aid                 0.131902\n",
       "food                      0.111997\n",
       "earthquake                0.091557\n",
       "shelter                   0.090221\n",
       "storm                     0.087326\n",
       "medical_help              0.079934\n",
       "floods                    0.079890\n",
       "water                     0.065194\n",
       "infrastructure_related    0.063903\n",
       "buildings                 0.051256\n",
       "dtype: float64"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "categories_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "category = list(df.columns[4:])\n",
    "for column_name in category:\n",
    "    df[[column_name]] = df[[column_name]].apply(pd.to_numeric)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[['related']] = df[['related']].apply(pd.to_numeric)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 22621 entries, 0 to 22620\n",
      "Data columns (total 34 columns):\n",
      "request                   22621 non-null int64\n",
      "offer                     22621 non-null int64\n",
      "aid_related               22621 non-null int64\n",
      "medical_help              22621 non-null int64\n",
      "medical_products          22621 non-null int64\n",
      "search_and_rescue         22621 non-null int64\n",
      "security                  22621 non-null int64\n",
      "military                  22621 non-null int64\n",
      "water                     22621 non-null int64\n",
      "food                      22621 non-null int64\n",
      "shelter                   22621 non-null int64\n",
      "clothing                  22621 non-null int64\n",
      "money                     22621 non-null int64\n",
      "missing_people            22621 non-null int64\n",
      "refugees                  22621 non-null int64\n",
      "death                     22621 non-null int64\n",
      "other_aid                 22621 non-null int64\n",
      "infrastructure_related    22621 non-null int64\n",
      "transport                 22621 non-null int64\n",
      "buildings                 22621 non-null int64\n",
      "electricity               22621 non-null int64\n",
      "tools                     22621 non-null int64\n",
      "hospitals                 22621 non-null int64\n",
      "shops                     22621 non-null int64\n",
      "aid_centers               22621 non-null int64\n",
      "other_infrastructure      22621 non-null int64\n",
      "weather_related           22621 non-null int64\n",
      "floods                    22621 non-null int64\n",
      "storm                     22621 non-null int64\n",
      "fire                      22621 non-null int64\n",
      "earthquake                22621 non-null int64\n",
      "cold                      22621 non-null int64\n",
      "other_weather             22621 non-null int64\n",
      "direct_report             22621 non-null int64\n",
      "dtypes: int64(34)\n",
      "memory usage: 5.9 MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>message</th>\n",
       "      <th>original</th>\n",
       "      <th>genre</th>\n",
       "      <th>related</th>\n",
       "      <th>request</th>\n",
       "      <th>offer</th>\n",
       "      <th>aid_related</th>\n",
       "      <th>medical_help</th>\n",
       "      <th>medical_products</th>\n",
       "      <th>search_and_rescue</th>\n",
       "      <th>security</th>\n",
       "      <th>military</th>\n",
       "      <th>child_alone</th>\n",
       "      <th>water</th>\n",
       "      <th>food</th>\n",
       "      <th>shelter</th>\n",
       "      <th>clothing</th>\n",
       "      <th>money</th>\n",
       "      <th>missing_people</th>\n",
       "      <th>refugees</th>\n",
       "      <th>death</th>\n",
       "      <th>other_aid</th>\n",
       "      <th>infrastructure_related</th>\n",
       "      <th>transport</th>\n",
       "      <th>buildings</th>\n",
       "      <th>electricity</th>\n",
       "      <th>tools</th>\n",
       "      <th>hospitals</th>\n",
       "      <th>shops</th>\n",
       "      <th>aid_centers</th>\n",
       "      <th>other_infrastructure</th>\n",
       "      <th>weather_related</th>\n",
       "      <th>floods</th>\n",
       "      <th>storm</th>\n",
       "      <th>fire</th>\n",
       "      <th>earthquake</th>\n",
       "      <th>cold</th>\n",
       "      <th>other_weather</th>\n",
       "      <th>direct_report</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>Weather update - a cold front from Cuba that c...</td>\n",
       "      <td>Un front froid se retrouve sur Cuba ce matin. ...</td>\n",
       "      <td>direct</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7</td>\n",
       "      <td>Is the Hurricane over or is it not over</td>\n",
       "      <td>Cyclone nan fini osinon li pa fini</td>\n",
       "      <td>direct</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8</td>\n",
       "      <td>Looking for someone but no name</td>\n",
       "      <td>Patnm, di Maryani relem pou li banm nouvel li ...</td>\n",
       "      <td>direct</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9</td>\n",
       "      <td>UN reports Leogane 80-90 destroyed. Only Hospi...</td>\n",
       "      <td>UN reports Leogane 80-90 destroyed. Only Hospi...</td>\n",
       "      <td>direct</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>12</td>\n",
       "      <td>says: west side of Haiti, rest of the country ...</td>\n",
       "      <td>facade ouest d Haiti et le reste du pays aujou...</td>\n",
       "      <td>direct</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id                                            message  \\\n",
       "0   2  Weather update - a cold front from Cuba that c...   \n",
       "1   7            Is the Hurricane over or is it not over   \n",
       "2   8                    Looking for someone but no name   \n",
       "3   9  UN reports Leogane 80-90 destroyed. Only Hospi...   \n",
       "4  12  says: west side of Haiti, rest of the country ...   \n",
       "\n",
       "                                            original   genre  related  \\\n",
       "0  Un front froid se retrouve sur Cuba ce matin. ...  direct        1   \n",
       "1                 Cyclone nan fini osinon li pa fini  direct        1   \n",
       "2  Patnm, di Maryani relem pou li banm nouvel li ...  direct        0   \n",
       "3  UN reports Leogane 80-90 destroyed. Only Hospi...  direct        1   \n",
       "4  facade ouest d Haiti et le reste du pays aujou...  direct        1   \n",
       "\n",
       "   request  offer  aid_related  medical_help  medical_products  \\\n",
       "0        0      0            0             0                 0   \n",
       "1        1      0            1             0                 0   \n",
       "2        0      0            0             0                 0   \n",
       "3        1      0            1             1                 1   \n",
       "4        1      0            1             0                 0   \n",
       "\n",
       "   search_and_rescue  security  military  child_alone  water  food  shelter  \\\n",
       "0                  0         0         0            0      0     0        0   \n",
       "1                  0         0         0            0      1     0        1   \n",
       "2                  0         0         0            0      0     0        0   \n",
       "3                  0         0         0            0      0     0        0   \n",
       "4                  0         0         0            0      1     0        0   \n",
       "\n",
       "   clothing  money  missing_people  refugees  death  other_aid  \\\n",
       "0         0      0               0         0      0          0   \n",
       "1         0      0               0         0      0          0   \n",
       "2         0      0               0         0      0          0   \n",
       "3         0      0               0         0      0          0   \n",
       "4         0      0               0         0      0          0   \n",
       "\n",
       "   infrastructure_related  transport  buildings  electricity  tools  \\\n",
       "0                       0          0          0            0      0   \n",
       "1                       0          0          0            0      0   \n",
       "2                       0          0          0            0      0   \n",
       "3                       0          0          0            0      0   \n",
       "4                       0          0          0            0      0   \n",
       "\n",
       "   hospitals  shops  aid_centers  other_infrastructure  weather_related  \\\n",
       "0          0      0            0                     0                0   \n",
       "1          0      0            0                     0                0   \n",
       "2          0      0            0                     0                0   \n",
       "3          0      0            0                     0                0   \n",
       "4          0      0            0                     0                0   \n",
       "\n",
       "   floods  storm  fire  earthquake  cold  other_weather  direct_report  \n",
       "0       0      0     0           0     0              0              0  \n",
       "1       0      0     0           0     0              0              1  \n",
       "2       0      0     0           0     0              0              0  \n",
       "3       0      0     0           0     0              0              1  \n",
       "4       0      0     0           0     0              0              1  "
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "genre\n",
       "direct    10747\n",
       "news       9480\n",
       "social     2394\n",
       "Name: message, dtype: int64"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "genre_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>related</th>\n",
       "      <th>request</th>\n",
       "      <th>offer</th>\n",
       "      <th>aid_related</th>\n",
       "      <th>medical_help</th>\n",
       "      <th>medical_products</th>\n",
       "      <th>search_and_rescue</th>\n",
       "      <th>security</th>\n",
       "      <th>military</th>\n",
       "      <th>water</th>\n",
       "      <th>food</th>\n",
       "      <th>shelter</th>\n",
       "      <th>clothing</th>\n",
       "      <th>money</th>\n",
       "      <th>missing_people</th>\n",
       "      <th>refugees</th>\n",
       "      <th>death</th>\n",
       "      <th>other_aid</th>\n",
       "      <th>infrastructure_related</th>\n",
       "      <th>transport</th>\n",
       "      <th>buildings</th>\n",
       "      <th>electricity</th>\n",
       "      <th>tools</th>\n",
       "      <th>hospitals</th>\n",
       "      <th>shops</th>\n",
       "      <th>aid_centers</th>\n",
       "      <th>other_infrastructure</th>\n",
       "      <th>weather_related</th>\n",
       "      <th>floods</th>\n",
       "      <th>storm</th>\n",
       "      <th>fire</th>\n",
       "      <th>earthquake</th>\n",
       "      <th>cold</th>\n",
       "      <th>other_weather</th>\n",
       "      <th>direct_report</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   related  request  offer  aid_related  medical_help  medical_products  \\\n",
       "0        1        0      0            0             0                 0   \n",
       "1        1        1      0            1             0                 0   \n",
       "2        0        0      0            0             0                 0   \n",
       "3        1        1      0            1             1                 1   \n",
       "4        1        1      0            1             0                 0   \n",
       "\n",
       "   search_and_rescue  security  military  water  food  shelter  clothing  \\\n",
       "0                  0         0         0      0     0        0         0   \n",
       "1                  0         0         0      1     0        1         0   \n",
       "2                  0         0         0      0     0        0         0   \n",
       "3                  0         0         0      0     0        0         0   \n",
       "4                  0         0         0      1     0        0         0   \n",
       "\n",
       "   money  missing_people  refugees  death  other_aid  infrastructure_related  \\\n",
       "0      0               0         0      0          0                       0   \n",
       "1      0               0         0      0          0                       0   \n",
       "2      0               0         0      0          0                       0   \n",
       "3      0               0         0      0          0                       0   \n",
       "4      0               0         0      0          0                       0   \n",
       "\n",
       "   transport  buildings  electricity  tools  hospitals  shops  aid_centers  \\\n",
       "0          0          0            0      0          0      0            0   \n",
       "1          0          0            0      0          0      0            0   \n",
       "2          0          0            0      0          0      0            0   \n",
       "3          0          0            0      0          0      0            0   \n",
       "4          0          0            0      0          0      0            0   \n",
       "\n",
       "   other_infrastructure  weather_related  floods  storm  fire  earthquake  \\\n",
       "0                     0                0       0      0     0           0   \n",
       "1                     0                0       0      0     0           0   \n",
       "2                     0                0       0      0     0           0   \n",
       "3                     0                0       0      0     0           0   \n",
       "4                     0                0       0      0     0           0   \n",
       "\n",
       "   cold  other_weather  direct_report  \n",
       "0     0              0              0  \n",
       "1     0              0              1  \n",
       "2     0              0              0  \n",
       "3     0              0              1  \n",
       "4     0              0              1  "
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "categories.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "#counts\n",
    "#cat_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "genre_counts = df.groupby('genre').count()['message']\n",
    "genre_names = list(genre_counts.index)\n",
    "    \n",
    "categories = df.iloc[:, 4:]\n",
    "cat_names = list(categories)\n",
    "cat_counts = [df[cat_name].sum() for cat_name in cat_names]\n",
    "    \n",
    "categories['sum'] = categories.sum(axis=1)\n",
    "counts = categories.groupby('sum').count()['related']\n",
    "names = list(counts.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot(graphs3, validate=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
